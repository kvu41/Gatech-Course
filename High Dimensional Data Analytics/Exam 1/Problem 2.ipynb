{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.396212594975001"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(X)\n",
    "m = np.sum(X)\n",
    "mean_X = m/n\n",
    "mean_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2066.340178602427"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logX = np.log(X)\n",
    "k = np.sum(logX)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gamma, polygamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(a):\n",
    "    dfda = n *(np.log(a/mean_X)-polygamma(1,a)) + k \n",
    "    return dfda\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(a):\n",
    "    f = (a-1)*k - n* np.log(gamma(a)) - a*k +n*a*np.log(a)-n*a\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.random.uniform(0.1, high =1, size =1)\n",
    "x0 = float(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = np.random.uniform(low = 0.1, high =1, size =1)\n",
    "y0 = float(y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "llh = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 0.001\n",
    "count = 1\n",
    "gradient = grad(x0)\n",
    "loss = []\n",
    "value =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2 loss 3.88859179737833\n",
      "iteration 3 loss 2.8850126407366457\n",
      "iteration 4 loss 2.049506733135502\n",
      "iteration 5 loss 1.684661366143675\n",
      "iteration 6 loss 1.8447191910357148\n",
      "iteration 7 loss 2.099542863608302\n",
      "iteration 8 loss 2.185545512336024\n",
      "iteration 9 loss 2.100059985571414\n",
      "iteration 10 loss 1.9665260980336046\n",
      "iteration 11 loss 1.913326217524627\n",
      "iteration 12 loss 1.9679404387124064\n",
      "iteration 13 loss 2.052552966891296\n",
      "iteration 14 loss 2.0857483897553197\n",
      "iteration 15 loss 2.050626751868416\n",
      "iteration 16 loss 1.99047497016279\n",
      "iteration 17 loss 1.9628112619427895\n",
      "iteration 18 loss 1.9871328284441854\n",
      "iteration 19 loss 2.0325369564567524\n",
      "iteration 20 loss 2.0553281605612232\n",
      "iteration 21 loss 2.0391754860896243\n",
      "iteration 22 loss 2.0035935003081944\n",
      "iteration 23 loss 1.9826359347370581\n",
      "iteration 24 loss 1.9933377400467749\n",
      "iteration 25 loss 2.022022766572694\n",
      "iteration 26 loss 2.040892732506317\n",
      "iteration 27 loss 2.034531125305285\n",
      "iteration 28 loss 2.011294363396281\n",
      "iteration 29 loss 1.9935246231200743\n",
      "iteration 30 loss 1.9966294132939275\n",
      "iteration 31 loss 2.0157127973445705\n",
      "iteration 32 loss 2.0321194952955612\n",
      "iteration 33 loss 2.0316000051311476\n",
      "iteration 34 loss 2.0161493404881625\n",
      "iteration 35 loss 2.000745826565995\n",
      "iteration 36 loss 1.9991792638477628\n",
      "iteration 37 loss 2.011709439588214\n",
      "iteration 38 loss 2.025941854234706\n",
      "iteration 39 loss 2.029099577058468\n",
      "iteration 40 loss 2.0192489558589894\n",
      "iteration 41 loss 2.006079781677062\n",
      "iteration 42 loss 2.0015955855205827\n",
      "iteration 43 loss 2.009210025893786\n",
      "iteration 44 loss 2.0212372235740705\n",
      "iteration 45 loss 2.0266551436324574\n",
      "iteration 46 loss 2.0211086156622633\n",
      "iteration 47 loss 2.0102229396497453\n",
      "iteration 48 loss 2.0040410205934744\n",
      "iteration 49 loss 2.007817535912889\n",
      "iteration 50 loss 2.0175495908804346\n",
      "iteration 51 loss 2.0241833231952926\n",
      "iteration 52 loss 2.0220121904442028\n",
      "iteration 53 loss 2.0134680938180556\n",
      "iteration 54 loss 2.0065164220831164\n",
      "iteration 55 loss 2.007295518588294\n",
      "iteration 56 loss 2.0146840536962296\n",
      "iteration 57 loss 2.0217147029155846\n",
      "iteration 58 loss 2.022150043143858\n",
      "iteration 59 loss 2.015944981637719\n",
      "iteration 60 loss 2.008955334798929\n",
      "iteration 61 loss 2.007469925436265\n",
      "iteration 62 loss 2.0125508355185766\n",
      "iteration 63 loss 2.0193280662069286\n",
      "iteration 64 loss 2.0216778780058235\n",
      "iteration 65 loss 2.017720291456566\n",
      "iteration 66 loss 2.011264623321374\n",
      "iteration 67 loss 2.0081878746180917\n",
      "iteration 68 loss 2.011096358480959\n",
      "iteration 69 loss 2.017118989047378\n",
      "iteration 70 loss 2.0207414908159915\n",
      "iteration 71 loss 2.0188440449785228\n",
      "iteration 72 loss 2.0133467597221277\n",
      "iteration 73 loss 2.0093016450346233\n",
      "iteration 74 loss 2.0102702374886268\n",
      "iteration 75 loss 2.015181083564072\n",
      "iteration 76 loss 2.019485152434635\n",
      "iteration 77 loss 2.01937200504169\n",
      "iteration 78 loss 2.015114370855969\n",
      "iteration 79 loss 2.010665063661697\n",
      "iteration 80 loss 2.0100096852443547\n",
      "iteration 81 loss 2.013593195932901\n",
      "iteration 82 loss 2.018051495267796\n",
      "iteration 83 loss 2.019375581004791\n",
      "iteration 84 loss 2.0165003570603193\n",
      "iteration 85 loss 2.0121362711759074\n",
      "iteration 86 loss 2.0102337315846666\n",
      "iteration 87 loss 2.0124105233569307\n",
      "iteration 88 loss 2.0165769427130065\n",
      "iteration 89 loss 2.018944268918932\n",
      "iteration 90 loss 2.0174645594454175\n",
      "iteration 91 loss 2.0135835680216494\n",
      "iteration 92 loss 2.010843631761752\n",
      "iteration 93 loss 2.011659131420558\n",
      "iteration 94 loss 2.015185118680791\n",
      "iteration 95 loss 2.018183227807608\n",
      "iteration 96 loss 2.017997225838531\n",
      "iteration 97 loss 2.014892254187193\n",
      "iteration 98 loss 2.0117273450506725\n",
      "iteration 99 loss 2.0113337716929585\n",
      "iteration 100 loss 2.013979923483617\n",
      "iteration 101 loss 2.0172076487508463\n",
      "iteration 102 loss 2.0181193837926643\n",
      "iteration 103 loss 2.0159710151948964\n",
      "iteration 104 loss 2.0127665484028667\n",
      "iteration 105 loss 2.0113988894849086\n",
      "iteration 106 loss 2.01303952783397\n",
      "iteration 107 loss 2.0161352089520204\n",
      "iteration 108 loss 2.0178803158460967\n",
      "iteration 109 loss 2.016756830788453\n",
      "iteration 110 loss 2.013844897298489\n",
      "iteration 111 loss 2.0117925329776027\n",
      "iteration 112 loss 2.012412200067245\n",
      "iteration 113 loss 2.015077751611642\n",
      "iteration 114 loss 2.017352503143453\n",
      "iteration 115 loss 2.017217729224697\n",
      "iteration 116 loss 2.0148563972198894\n",
      "iteration 117 loss 2.012432651011529\n",
      "iteration 118 loss 2.0121145585028035\n",
      "iteration 119 loss 2.01413323253672\n",
      "iteration 120 loss 2.016624589085381\n",
      "iteration 121 loss 2.017353027731311\n",
      "iteration 122 loss 2.0157129022416203\n",
      "iteration 123 loss 2.0132250673405134\n",
      "iteration 124 loss 2.0121325097832874\n",
      "iteration 125 loss 2.0133788514303883\n",
      "iteration 126 loss 2.0157930742591486\n",
      "iteration 127 loss 2.017190999483301\n",
      "iteration 128 loss 2.0163499462705867\n",
      "iteration 129 loss 2.014072285341679\n",
      "iteration 130 loss 2.0124248057688514\n",
      "iteration 131 loss 2.012866108904949\n",
      "iteration 132 loss 2.014953560140559\n",
      "iteration 133 loss 2.0167841837421543\n",
      "iteration 134 loss 2.016730341059889\n",
      "iteration 135 loss 2.014882229884218\n",
      "iteration 136 loss 2.0129288515673687\n",
      "iteration 137 loss 2.012618295304451\n",
      "iteration 138 loss 2.0141923931997594\n",
      "iteration 139 loss 2.0162027958117625\n",
      "iteration 140 loss 2.0168452321358705\n",
      "iteration 141 loss 2.015576076706131\n",
      "iteration 142 loss 2.013568154165305\n",
      "iteration 143 loss 2.012630638773892\n",
      "iteration 144 loss 2.0135795128073934\n",
      "iteration 145 loss 2.015526881882846\n",
      "iteration 146 loss 2.0167125715222105\n",
      "iteration 147 loss 2.016094445841255\n",
      "iteration 148 loss 2.0142606384026283\n",
      "iteration 149 loss 2.0128730444006324\n",
      "iteration 150 loss 2.0131631752726222\n",
      "iteration 151 loss 2.0148379857722443\n",
      "iteration 152 loss 2.0163732245868617\n",
      "iteration 153 loss 2.0164014271844497\n",
      "iteration 154 loss 2.0149269880980265\n",
      "iteration 155 loss 2.0132950764196464\n",
      "iteration 156 loss 2.0129670229635006\n",
      "iteration 157 loss 2.0142111381878904\n",
      "iteration 158 loss 2.0158851573406875\n",
      "iteration 159 loss 2.0164861409920523\n",
      "iteration 160 loss 2.015498196451849\n",
      "iteration 161 loss 2.013832603544615\n",
      "iteration 162 loss 2.0129897129248726\n",
      "iteration 163 loss 2.013707938388323\n",
      "iteration 164 loss 2.015316331242007\n",
      "iteration 165 loss 2.0163617898711745\n",
      "iteration 166 loss 2.015921621944859\n",
      "iteration 167 loss 2.014415369078583\n",
      "iteration 168 loss 2.0132070431476867\n",
      "iteration 169 loss 2.013371375059781\n",
      "iteration 170 loss 2.014737048830297\n",
      "iteration 171 loss 2.0160624076786156\n",
      "iteration 172 loss 2.016165026046812\n",
      "iteration 173 loss 2.0149746776530035\n",
      "iteration 174 loss 2.0135762500356758\n",
      "iteration 175 loss 2.0132228396794587\n",
      "iteration 176 loss 2.014212533516244\n",
      "iteration 177 loss 2.015637732308929\n",
      "iteration 178 loss 2.016218294382359\n",
      "iteration 179 loss 2.0154504122820054\n",
      "iteration 180 loss 2.0140419296130396\n",
      "iteration 181 loss 2.0132615428685963\n",
      "iteration 182 loss 2.013796485167875\n",
      "iteration 183 loss 2.015146803700999\n",
      "iteration 184 loss 2.016092788767726\n",
      "iteration 185 loss 2.01579670078828\n",
      "iteration 186 loss 2.014542883012544\n",
      "iteration 187 loss 2.013466280912254\n",
      "iteration 188 loss 2.013526232584216\n",
      "iteration 189 loss 2.014650999253783\n",
      "iteration 190 loss 2.0158185191236577\n",
      "iteration 191 loss 2.0159857228369757\n",
      "iteration 192 loss 2.015019118964457\n",
      "iteration 193 loss 2.013799247751898\n",
      "iteration 194 loss 2.0134199166779854\n",
      "iteration 195 loss 2.014207254995372\n",
      "iteration 196 loss 2.015439538825943\n",
      "iteration 197 loss 2.0160093656710685\n",
      "iteration 198 loss 2.0154182659153417\n",
      "iteration 199 loss 2.0142113777729\n",
      "iteration 200 loss 2.0134759052156137\n",
      "iteration 201 loss 2.0138621778155765\n",
      "iteration 202 loss 2.015008134634382\n",
      "iteration 203 loss 2.015878673649639\n",
      "iteration 204 loss 2.0157007466933696\n",
      "iteration 205 loss 2.014648560721053\n",
      "iteration 206 loss 2.0136743889483237\n",
      "iteration 207 loss 2.0136476356034962\n",
      "iteration 208 loss 2.0145784871046533\n",
      "iteration 209 loss 2.0156212693305515\n",
      "iteration 210 loss 2.0158432333963554\n",
      "iteration 211 loss 2.0150580064977217\n",
      "iteration 212 loss 2.013980870396208\n",
      "iteration 213 loss 2.0135782308978953\n",
      "iteration 214 loss 2.0142005089724306\n",
      "iteration 215 loss 2.015277129360785\n",
      "iteration 216 loss 2.0158401079755586\n",
      "iteration 217 loss 2.01539405774143\n",
      "iteration 218 loss 2.0143510590917995\n",
      "iteration 219 loss 2.0136508405533626\n",
      "iteration 220 loss 2.013914523998354\n",
      "iteration 221 loss 2.014893257230174\n",
      "iteration 222 loss 2.0157028808224298\n",
      "iteration 223 loss 2.015622844930368\n",
      "iteration 224 loss 2.0147365532502546\n",
      "iteration 225 loss 2.013846165747377\n",
      "iteration 226 loss 2.013747331917968\n",
      "iteration 227 loss 2.0145178918206565\n",
      "iteration 228 loss 2.0154577414293193\n",
      "iteration 229 loss 2.015725336889742\n",
      "iteration 230 loss 2.015090630851064\n",
      "iteration 231 loss 2.014132012410761\n",
      "iteration 232 loss 2.0137100297057606\n",
      "iteration 233 loss 2.0141949162339214\n",
      "iteration 234 loss 2.015141609566095\n",
      "iteration 235 loss 2.0156985382876247\n",
      "iteration 236 loss 2.0153734957442535\n",
      "iteration 237 loss 2.0144678387380615\n",
      "iteration 238 loss 2.013797746159773\n",
      "iteration 239 loss 2.0139590832930097\n",
      "iteration 240 loss 2.014797203367321\n",
      "iteration 241 loss 2.0155548016053673\n",
      "iteration 242 loss 2.0155564195238713\n",
      "iteration 243 loss 2.014809984583062\n",
      "iteration 244 loss 2.0139912218258447\n",
      "iteration 245 loss 2.013832558102144\n",
      "iteration 246 loss 2.0144677278987237\n",
      "iteration 247 loss 2.0153194306971165\n",
      "iteration 248 loss 2.0156243725722476\n",
      "iteration 249 loss 2.0151169491357637\n",
      "iteration 250 loss 2.0142599570647857\n",
      "iteration 251 loss 2.013823107922827\n",
      "iteration 252 loss 2.014191805802112\n",
      "iteration 253 loss 2.0150269347614267\n",
      "iteration 254 loss 2.0155769277118796\n",
      "iteration 255 loss 2.015354110242446\n",
      "iteration 256 loss 2.0145664826896796\n",
      "iteration 257 loss 2.0139240661125486\n",
      "iteration 258 loss 2.0139992193082987\n",
      "iteration 259 loss 2.014716427122012\n",
      "iteration 260 loss 2.015427424685766\n",
      "iteration 261 loss 2.015497373715178\n",
      "iteration 262 loss 2.0148711990029375\n",
      "iteration 263 loss 2.0141159851300072\n",
      "iteration 264 loss 2.0139079169190213\n",
      "iteration 265 loss 2.0144267392908235\n",
      "iteration 266 loss 2.0152005805338686\n",
      "iteration 267 loss 2.015535389242188\n",
      "iteration 268 loss 2.0151371906107336\n",
      "iteration 269 loss 2.0143696997303278\n",
      "iteration 270 loss 2.0139225727072443\n",
      "iteration 271 loss 2.0141918301448354\n",
      "iteration 272 loss 2.014928899068576\n",
      "iteration 273 loss 2.0154701514591884\n",
      "iteration 274 loss 2.0153344570419582\n",
      "iteration 275 loss 2.0146503686864095\n",
      "iteration 276 loss 2.01403479205596\n",
      "iteration 277 loss 2.0140370126409537\n",
      "iteration 278 loss 2.014648354862765\n",
      "iteration 279 loss 2.015315998516002\n",
      "iteration 280 loss 2.0154430952011526\n",
      "iteration 281 loss 2.0149219687494986\n",
      "iteration 282 loss 2.0142248590349623\n",
      "iteration 283 loss 2.0139764039082433\n",
      "iteration 284 loss 2.014393891235872\n",
      "iteration 285 loss 2.0150972042825597\n",
      "iteration 286 loss 2.015455114423425\n",
      "iteration 287 loss 2.01515168689327\n",
      "iteration 288 loss 2.014464742105987\n",
      "iteration 289 loss 2.014011843562836\n",
      "iteration 290 loss 2.0141952716751694\n",
      "iteration 291 loss 2.014844514427943\n",
      "iteration 292 loss 2.0153747392905794\n",
      "iteration 293 loss 2.0153136960547022\n",
      "iteration 294 loss 2.01472193782359\n",
      "iteration 295 loss 2.0141333400682204\n",
      "iteration 296 loss 2.0140737610940596\n",
      "iteration 297 loss 2.0145910849156183\n",
      "iteration 298 loss 2.0152172383360742\n",
      "iteration 299 loss 2.015391897351953\n",
      "iteration 300 loss 2.014963651842204\n",
      "iteration 301 loss 2.0143209192797635\n",
      "iteration 302 loss 2.014039995795411\n",
      "iteration 303 loss 2.014368333045318\n",
      "iteration 304 loss 2.0150064874939044\n",
      "iteration 305 loss 2.015381353553786\n",
      "iteration 306 loss 2.015160800025\n",
      "iteration 307 loss 2.014547586050707\n",
      "iteration 308 loss 2.0140932441409234\n",
      "iteration 309 loss 2.014202201369665\n",
      "iteration 310 loss 2.0147716170057417\n",
      "iteration 311 loss 2.015288305789955\n",
      "iteration 312 loss 2.015291358538818\n",
      "iteration 313 loss 2.01478298844484\n",
      "iteration 314 loss 2.01422208383344\n",
      "iteration 315 loss 2.0141102659511345\n",
      "iteration 316 loss 2.0145431846989346\n",
      "iteration 317 loss 2.015128837844937\n",
      "iteration 318 loss 2.015342691725464\n",
      "iteration 319 loss 2.0149973079859382\n",
      "iteration 320 loss 2.0144063487923862\n",
      "iteration 321 loss 2.014100001858594\n",
      "iteration 322 loss 2.0143493575081215\n",
      "iteration 323 loss 2.0149264100761246\n",
      "iteration 324 loss 2.0153126256934253\n",
      "iteration 325 loss 2.0151648940339166\n",
      "iteration 326 loss 2.0146200503789267\n",
      "iteration 327 loss 2.0141683660260123\n",
      "iteration 328 loss 2.0142125635307364\n",
      "iteration 329 loss 2.014708610623834\n",
      "iteration 330 loss 2.015209195824488\n",
      "iteration 331 loss 2.0152672134393406\n",
      "iteration 332 loss 2.0148348718467086\n",
      "iteration 333 loss 2.014302690367475\n",
      "iteration 334 loss 2.0141470023045076\n",
      "iteration 335 loss 2.0145035516926075\n",
      "iteration 336 loss 2.0150491582584644\n",
      "iteration 337 loss 2.0152947887394954\n",
      "iteration 338 loss 2.01502378276826\n",
      "iteration 339 loss 2.014482717726608\n",
      "iteration 340 loss 2.014157281547443\n",
      "iteration 341 loss 2.0143363651328063\n",
      "iteration 342 loss 2.014855500182092\n",
      "iteration 343 loss 2.0152479347351004\n",
      "iteration 344 loss 2.015164325779521\n",
      "iteration 345 loss 2.014683479798351\n",
      "iteration 346 loss 2.0142383000516424\n",
      "iteration 347 loss 2.0142262224195515\n",
      "iteration 348 loss 2.0146542952557938\n",
      "iteration 349 loss 2.0151362566267865\n",
      "iteration 350 loss 2.015241187805067\n",
      "iteration 351 loss 2.0148786253780275\n",
      "iteration 352 loss 2.014376338102279\n",
      "iteration 353 loss 2.0141842241047456\n",
      "iteration 354 loss 2.014471316734153\n",
      "iteration 355 loss 2.014977024337083\n",
      "iteration 356 loss 2.01524777206681\n",
      "iteration 357 loss 2.0150437687379763\n",
      "iteration 358 loss 2.0145511689783793\n",
      "iteration 359 loss 2.0142123838327235\n",
      "iteration 360 loss 2.01432883508963\n",
      "iteration 361 loss 2.014792669576219\n",
      "iteration 362 loss 2.015186621043965\n",
      "iteration 363 loss 2.01515944401791\n",
      "iteration 364 loss 2.014738886153157\n",
      "iteration 365 loss 2.014303787966527\n",
      "iteration 366 loss 2.0142429887001168\n",
      "iteration 367 loss 2.0146077497946355\n",
      "iteration 368 loss 2.015068686904529\n",
      "iteration 369 loss 2.0152133176756335\n",
      "iteration 370 loss 2.0149150646904146\n",
      "iteration 371 loss 2.0144438625874206\n",
      "iteration 372 loss 2.014222031224508\n",
      "iteration 373 loss 2.0144457758222933\n",
      "iteration 374 loss 2.014911586953668\n",
      "iteration 375 loss 2.0152014168494445\n",
      "iteration 376 loss 2.015057849807868\n",
      "iteration 377 loss 2.0146125442354763\n",
      "iteration 378 loss 2.0142656392611045\n",
      "iteration 379 loss 2.0143263025219653\n",
      "iteration 380 loss 2.0147371008584987\n",
      "iteration 381 loss 2.015128262353863\n",
      "iteration 382 loss 2.0151505915709707\n",
      "iteration 383 loss 2.014787046016391\n",
      "iteration 384 loss 2.014365324729723\n",
      "iteration 385 loss 2.0142626350076522\n",
      "iteration 386 loss 2.0145682503284674\n",
      "iteration 387 loss 2.0150059342167506\n",
      "iteration 388 loss 2.0151837166104687\n",
      "iteration 389 loss 2.0149448487390584\n",
      "iteration 390 loss 2.014505856355511\n",
      "iteration 391 loss 2.01426041377298\n",
      "iteration 392 loss 2.0144263414501355\n",
      "iteration 393 loss 2.01485222822518\n",
      "iteration 394 loss 2.0151556347219\n",
      "iteration 395 loss 2.0150665336145392\n",
      "iteration 396 loss 2.0146674715898576\n",
      "iteration 397 loss 2.014317222605179\n",
      "iteration 398 loss 2.0143283412676003\n",
      "iteration 399 loss 2.014688168564096\n",
      "iteration 400 loss 2.0150726056856443\n",
      "iteration 401 loss 2.0151381082480406\n",
      "iteration 402 loss 2.014828569426696\n",
      "iteration 403 loss 2.0144232293526585\n",
      "iteration 404 loss 2.0142849056090117\n",
      "iteration 405 loss 2.0145352121996662\n",
      "iteration 406 loss 2.014947623416678\n",
      "iteration 407 loss 2.0151525546694296\n",
      "iteration 408 loss 2.014968526215593\n",
      "iteration 409 loss 2.0145627389920255\n",
      "iteration 410 loss 2.0142992824345125\n",
      "iteration 411 loss 2.0144125075546184\n",
      "iteration 412 loss 2.01479849457595\n",
      "iteration 413 loss 2.0151104356672143\n",
      "iteration 414 loss 2.015070275117775\n",
      "iteration 415 loss 2.014716427679833\n",
      "iteration 416 loss 2.0143671967528194\n",
      "iteration 417 loss 2.0143345509715203\n",
      "iteration 418 loss 2.0146453829330557\n",
      "iteration 419 loss 2.015019519308961\n",
      "iteration 420 loss 2.015122333476963\n",
      "iteration 421 loss 2.014863949101317\n",
      "iteration 422 loss 2.01447769519229\n",
      "iteration 423 loss 2.0143095228618804\n",
      "iteration 424 loss 2.014508148351654\n",
      "iteration 425 loss 2.0148935055915724\n",
      "iteration 426 loss 2.0151200437071544\n",
      "iteration 427 loss 2.014986569067482\n",
      "iteration 428 loss 2.0146148073600245\n",
      "iteration 429 loss 2.014338490021713\n",
      "iteration 430 loss 2.014403824128776\n",
      "iteration 431 loss 2.0147500485729326\n",
      "iteration 432 loss 2.015065900697263\n",
      "iteration 433 loss 2.0150694937600155\n",
      "iteration 434 loss 2.0147597825564043\n",
      "iteration 435 loss 2.0144155443362077\n",
      "iteration 436 loss 2.014344547696572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 437 loss 2.0146083492006284\n",
      "iteration 438 loss 2.0149689579672216\n",
      "iteration 439 loss 2.015103608226247\n",
      "iteration 440 loss 2.014893596145042\n",
      "iteration 441 loss 2.0145288264978847\n",
      "iteration 442 loss 2.014336191969153\n",
      "iteration 443 loss 2.0144866390685725\n",
      "iteration 444 loss 2.0148434208460153\n",
      "iteration 445 loss 2.0150864265466963\n",
      "iteration 446 loss 2.014999396857153\n",
      "iteration 447 loss 2.0146622722988337\n",
      "iteration 448 loss 2.0143778473853016\n",
      "iteration 449 loss 2.0143998788125494\n",
      "iteration 450 loss 2.0147066336669472\n",
      "iteration 451 loss 2.015022161653401\n",
      "iteration 452 loss 2.0150645858342946\n",
      "iteration 453 loss 2.0147978325676617\n",
      "iteration 454 loss 2.0144621911618805\n",
      "iteration 455 loss 2.014357957301564\n",
      "iteration 456 loss 2.014576737748017\n",
      "iteration 457 loss 2.0149209370834873\n",
      "iteration 458 loss 2.0150822760972797\n",
      "iteration 459 loss 2.014917866218674\n",
      "iteration 460 loss 2.0145766655490824\n",
      "iteration 461 loss 2.014364604860552\n",
      "iteration 462 loss 2.0144703098483663\n",
      "iteration 463 loss 2.0147972706494284\n",
      "iteration 464 loss 2.0150519685751944\n",
      "iteration 465 loss 2.0150073944978044\n",
      "iteration 466 loss 2.0147052858947583\n",
      "iteration 467 loss 2.0144171356203957\n",
      "iteration 468 loss 2.0144002836105046\n",
      "iteration 469 loss 2.014668048005213\n",
      "iteration 470 loss 2.014979385798441\n",
      "iteration 471 loss 2.0150559332420035\n",
      "iteration 472 loss 2.0148308247507027\n",
      "iteration 473 loss 2.014507024030157\n",
      "iteration 474 loss 2.014374411006786\n",
      "iteration 475 loss 2.0145502620156064\n",
      "iteration 476 loss 2.014875513188951\n",
      "iteration 477 loss 2.015058683603752\n",
      "iteration 478 loss 2.0149370788272387\n",
      "iteration 479 loss 2.0146212132055483\n",
      "iteration 480 loss 2.0143944436609833\n",
      "iteration 481 loss 2.014458815198043\n",
      "iteration 482 loss 2.014754996942297\n",
      "iteration 483 loss 2.0150169508787763\n",
      "iteration 484 loss 2.01501092511121\n",
      "iteration 485 loss 2.0147439620323344\n",
      "iteration 486 loss 2.014456115785089\n",
      "iteration 487 loss 2.014404665438219\n",
      "iteration 488 loss 2.014634124761065\n",
      "iteration 489 loss 2.0149377637110346\n",
      "iteration 490 loss 2.015043909497299\n",
      "iteration 491 loss 2.014858975074091\n",
      "iteration 492 loss 2.014549904621903\n",
      "iteration 493 loss 2.014393542690731\n",
      "iteration 494 loss 2.0145286620812897\n",
      "iteration 495 loss 2.0148327687665213\n",
      "iteration 496 loss 2.015033179716397\n",
      "iteration 497 loss 2.014951531545984\n",
      "iteration 498 loss 2.014662444733857\n",
      "iteration 499 loss 2.014425383992038\n",
      "iteration 500 loss 2.014451826823761\n"
     ]
    }
   ],
   "source": [
    "while gradient > tol or count < 500:\n",
    "    x = y0 - 0.001*gradient\n",
    "    y0 = x +(count-1)/(count+2) *(x -x0)\n",
    "    gradient = grad(x)\n",
    "    x0 = x\n",
    "    llh.append(log_likelihood(x0))\n",
    "    count = count +1\n",
    "    value.append(x0)\n",
    "    loss.append(x0)\n",
    "    print('iteration', count, 'loss', x0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Log-Likelihood')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = list(range(1,101))\n",
    "\n",
    "plt.plot(i, llh[0:100], linewidth = 2)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Log-Likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Accelerated Gradient Descent converged after 42 iteration and Alpha = 2.01471, Beta = 0.23995 '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" The Accelerated Gradient Descent converged after 42 iteration and Alpha = 2.01471, Beta = 0.23995 \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hess(a):\n",
    "    f = n * 1/a - n*polygamma(2,a)\n",
    "    return f\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.random.uniform(low =1, high =1, size =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "llog =[]\n",
    "values = []\n",
    "for i in range(0,100):\n",
    "    x = x0 - grad(x0)/hess(x0)\n",
    "    x0 =x\n",
    "    s = log_likelihood(x0)\n",
    "    llog.append(s)\n",
    "    values.append(x0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Log_likelihood')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i  = list(range(0,10))\n",
    "plt.plot(i, llog[0:10], linewidth = 2)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Log_likelihood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.01471874])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Value of alpha is 2.01471 and beta is 0.23994'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Value of alpha is 2.01471 and beta is 0.23994\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
